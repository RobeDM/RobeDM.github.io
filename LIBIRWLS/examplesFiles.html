<!DOCTYPE html>
<html lang="en">

        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="LIBIRWLS, parallel IRWLS algorithm for SVMs">
        <meta name="author" content="Roberto Diaz Morales">
                            
        <title>Install LIBIRWLS</title>
                          
        <!-- Bootstrap Core CSS -->
        <link href="css/bootstrap.min.css" rel="stylesheet">
                                
        <!-- Custom CSS -->
        <link href="css/modern-business.css" rel="stylesheet">
                                    
        <!-- Custom CSS -->
        <link href="css/command.css" rel="stylesheet">
                                        
                                        
        <!-- Custom Fonts -->
        <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
                                            
        <!-- USED FOR LATEX CODE INSIDE THE HTML -->
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
                     extensions: ["tex2jax.js"],
                     jax: ["input/TeX","output/HTML-CSS"],
                     tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]}
                                                                   });
        </script>
        <script type="text/javascript" src="MathJax/MathJax.js"></script>
                                            
        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->
                                            
    </head>


<body>

<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="index.html">LIBIRWLS</a>
        </div>
        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Install<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li>
                            <a href="install.html">Build the library</a>
                        </li>
                        <li>
                            <a href="installpython.html">Python Extension</a>
                        </li>
                    </ul>
                </li>

                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Algorithms <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li>
                            <a href="PIRWLS.html">IRWLS to train a SVM</a>
                        </li>
                        <li>
                            <a href="PSIRWLS.html">IRWLS to train a budgeted SVM</a>
                        </li>
                        <li>
                            <a href="parallelization.html">Parallelization</a>
                        </li>
                    </ul>
                </li>
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Examples<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li>
                            <a href="examplesFiles.html">Command Line guide and Examples</a>
                        </li>
                        <li>
                            <a href="examplesPython.html">Python Extension guide and Examples</a>
                        </li>
                        <li>
                            <a href="examplesDemos.html">Demo folder</a>
                        </li>
                    </ul>
                </li>

                <li>
                    <a href="API/index.html" target="blank">API</a>
                </li>
                <li>
                    <a href="contact.html">Contact</a>
                </li>
                <li><a href="https://github.com/RobeDM/LIBIRWLS" target="blank"><i class="fa fa-github fa-fw fa-lg"></i></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

    <!-- Header Carousel -->


    <!-- Page Content -->
    <div class="container container-large">

        <!-- Marketing Icons Section -->
        <div class="row">
            <div class="col-md-1">
            </div>
            <div class="col-md-10">

                <hr>

                <h1>
                COMMAND LINE
                </h1>

                <hr>

                <h2>
                Commands:
                </h2>
                
                <p>
                    This library can currently currently train <a href="PIRWLS.html">full SVMs</a> and <a href="PSIRWLS.html">Budgeted SVMs</a>. Once this library has been <a href="install.html">compiled</a>, you can find the executable files under the folder "bin". The syntax to train a model is very intuitive a similar to other svm based tools like libsvm or svmlight.</p>
                 <p>
To train a model using the algorithms you must use their respective commands followed by the options (see <a href="#options">options</a> section), the file that contains the labeled training set (see <a href="#datasets">datasets</a> section to see the supported formats) and the file where the trained model will be saved (see <a href="#modelfiles">model file</a> section): 
                <ul>
                <li>./full-train [options] training_set_file model_file</li>
                <li>./budgeted-train [options] training_set_file model_file</li>
                </ul>
                </p>
                <p>
To classify a new dataset you must specify the command LIBIRWLS-predict followed by the options (see <a href="#options">options</a> section), the file that contains the dataset to classify (it can be a labeled or unalbeled dataset, see <a href="#datasets">datasets</a> section to see the supported formats), the file that contains a trained model (previously obtained using the algorithms, see <a href="#modelfiles">model file</a> section) and finally the file to save the classification of the dataset (see <a href="#output">output</a> section):
 
                <ul>
                <li>./LIBIRWLS-predict [options] dataset_file model_file output_file</li>
                </ul>
                </p>

                <h2>
                <a name="options"></a>Options:
                </h2>


                <h3>
                Training options:
                </h3>
                
                <p><b>General options</b></p>

                <p>
                <ul>
                <li>-k kernel type (see <a href="PIRWLS.html">algorithms</a>, default 1):
                    <ul>
                    <li>0 = Linear kernel u'v</li>
                    <li>1 = radial basis function exp(-gamma|u-v|^2)</li>
                    </ul>
                </li>
                <li>-g Gamma: Set gamma in the radial basis kernel function (see <a href="PIRWLS.html">algorithms</a>, default 1)</li>
                <li>-c Cost: Set the SVM Cost (see <a href="PIRWLS.html">algorithms</a>, default 1)</li>
                <li>-t Number_of_Threads: It is the number of parallel threads (see <a href="parallelization.html">parallelization</a>, default 1)</li>
                <li>-f File format (see <a href="#datasets">datasets</a>, default 1):
                    <ul>
                        <li>0 = CSV format</li>
                        <li>1 = libsvm format</li>
                    </ul>
                </li>
                <li>-p separator: csv separator character (only applicable if CSV format is selected, default ",")</li>
                <li>-v verbose (default 1): 
                    <ul>
                        <li>0 = Silen mode, no screen messages</li>
                        <li>1 = Screen messages</li>
                    </ul>
                </li>
                </ul>
                </p>

                <p><b>Specific options of full-train</b></p>
                <p>
                <ul>
                <li>-w Working_set_size: Size of the Least Squares Problem in every iteration (default 500)</li>
                <li>-e eta: Stop criteria (default 0.001)</li>
                </ul>
                </p>

                <p><b>Specific options of budgeted-train</b></p>
                <p>
                <ul>
                <li>-s Classifier_size: Size of the classifier (see <a href="PSIRWLS.html">PSIRWLS</a>, default 50)</li>
                <li>-a Algorithm: Algorithm for centroids selection (see <a href="PSIRWLS.html">PSIRWLS</a>,default 1)
                    <ul>
                        <li>0 = Random Selection</li>
                        <li>1 = SGMA (Sparse Greedy Matrix Approximation)</li>
                    </ul>
                </li>
                </ul>
                </p>


                <h3>
                Classification options:
                </h3>

                <p>To use with the command LIBIRWLS-predict.</p>

                <p>
                <ul>
                <li>-s Soft output (see <a href="#output">output</a>, default 0):</li>
                <ul>
                <li>0 Hard classification (class prediction)</li>
                <li>1 Soft classification</li>
                </ul>
                <li>-l Labeled: (see <a href="#datasets">datasets</a>, default 0)</li>
                <ul>
                <li>1 if the dataset is labeled </li>
                <li>0 if the dataset is unlabeled</li>
                <li>-t Number_of_Threads: It is the number of parallel threads (see <a href="parallelization.html">parallelization</a>, default 1)</li>
                <li>-f File format (see <a href="#datasets">datasets</a>, default 1):
                    <ul>
                        <li>0 = CSV format</li>
                        <li>1 = libsvm format</li>
                    </ul>
                </li>
                <li>-p separator: csv separator character (only applicable if CSV format is selected, default ",")</li>
                <li>-v verbose (default 1): 
                    <ul>
                        <li>0 = Silen mode, no screen messages</li>
                        <li>1 = Screen messages</li>
                    </ul>
                </li>
                </ul>
                </ul>
                </p>

                <h2>
                <a name="datasets"></a>Dataset Files:
                </h2>
                
                <p>
                This library supports datasets in two different file formats LibSVM and CSV (the format must be specified using the <a href="#options">options</a>). The datasets must be labeled for training and labeled or unlabeled for testing. The labels must take values +1 and -1. 
                </p>

                <p>
                You can find a high number of datasets in libSVM format in the <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/">libsvm repository</a>. You can test this library with them, take into account that many of them don't have labels with values +1 and -1 and you need to adapt them.
                </p>


                <p>
                <b>LibSVM format</b>
                </p>

                <p>
                Labeled - Every line is a sample and is composed by the class (+1 or -1) and followed by pairs of feature index  feature value:
                <br><br>
                    +1 1:5 7:2 15:6<br>
                    +1 1:5 7:2 13:6 23:3<br>
                    -1 2:4 7:3 10:6 23:1<br>
                </p>

                <p>
                Unlabeled - Every line is a sample and is composed by pairs of feature index and feature value:
                <br><br>
                    1:5 7:2 15:6<br>
                    1:5 7:2 13:6 23:3<br>
                    2:4 7:3 10:6 23:1<br>
                </p>

                <p>
                    <b>CSV format</b>
                </p>

                <p>
Each line of the file is a data record. Each record consists of one or more fields, separated by commas (the separator character can be modified using the command <a href="#options">options</a>).
                </p>
                <p>
                Labeled - The first value of every row must tell the class of the data and must take +1 or -1 value:
                <br><br>
                    +1,5,0,0,3,0,0,25<br>
                    +1,5,0,2,0,6,3,0<br>
                    -1,0,4,3,0,0,6,1<br>
                </p>

                <p>

                Unlabeled - Every line contains only the value of every feature

                <br><br>
                    5,0,0,3,0,0,25<br>
                    5,0,2,0,6,3,0<br>
                    0,4,3,0,0,6,1<br>
                </p>

                <h2>
                <a name="modelfiles"></a>Model Files:
                </h2>

                <p>
                The model files store a trined classifier and they are not directly editable. They contain the numerical values of the model in binary format.
                </p>

                <h2>
                <a name="output"></a>Output Files:
                </h2>

                <p>                
                The classification function of the SVM takes the form of a linear combination of kernel functions:
                </p>
                    <p align="center">
                    $f(\mathbf{x_i})=\sum_{j=1}^m\beta_j K(\mathbf{x}_i,\mathbf{c}_j)$
                    </p>
                <p>
                If this value is positive, the sample will be classified as class +1. Otherwise, the data will be classified as -1. A hard classification directly tell the class, a soft classification tell the output of this classification function. 
                </p>

                <p>

                When we use the command "LIBIRWLS-predict" to classify a dataset the result will be stored in a file where every row is the classification of a data. The format (soft or hard) can be specified using the <a href="#options">options</a>.
                </p>


                <h2>Examples</h2>

                <h3>Example 1 - Training using full-train</h3>

                <p>
                If you have a training set in a file called "training.txt" with libsvm format (-f 1) and you want to create a classifier using our full SVM training procedure (full-train command) with gaussian kernel (-k 1), gamma = 0.001 (-g 0.001), cost = 1000 (-c 1000) and using 4 threads to speed up the training (-t 4) you can use the following command:
                </p>

                <p>
                <div class="shell-wrap">
                    <p class="shell-top-bar">/Users/robedm/LIBIRWLS</p>
                    <ul class="shell-body">
                        <li>./bin/full-train -k 1 -g 0.001 -c 1000 -f 1 -t 4 training.txt model.mod</li>
                    </ul>
                </div>
                </p>

                <p>
                The classifier will be saved in a file called "model.mod".
                </p>

                <p>
                In this example the options -k 1 and -f 1 are not neccesary because they are the default values of these parameters.
                </p>


                <h3>Example 2 - Training using budgeted-train</h3>

                <p>
                If you have a training set in a file called "training.csv" with csv format (-f 0) and for computational reasons you want to obtain an approximate solution (budgeted-train command) with a fixed classifier size = 100 (-s 100) with gaussian kernel (-k 1), gamma = 0.1 (-g 0.1), cost = 10 (-c 10) and using 2 threads to speed up the training (-t 2) you can use the following command:
                </p>

                <p>
                <div class="shell-wrap">
                    <p class="shell-top-bar">/Users/robedm/LIBIRWLS</p>
                    <ul class="shell-body">
                        <li>./bin/budgeted-train -k 1 -g 0.1 -a 0 -s 100 -c 10 -f 0 -t 2 training.csv model2.mod</li>
                    </ul>
                </div>
                </p>

                <p>
                The classifier will be saved in a file called "model2.mod".
                </p>


                <h3>Example 3 - Classification</h3>

                <p>If you want to use the model created in the Example 2 (model2.mod) to classifiy a labeled dataset (-l 1) stored in a file called "test.txt" with libsvm format (-f 1) and save the hard predictions (-s 1, see <a href="#output">outputs</a>) in a file called output.txt you can use this command:</p>
                <p>
                <div class="shell-wrap">
                    <p class="shell-top-bar">/Users/robedm/LIBIRWLS</p>
                    <ul class="shell-body">
                        <li>./bin/LIBIRWLS-predict -f 1 -l 1 test.txt model2.mod output.txt</li>
                    </ul>
                </div>
                </p>

        <hr>

        <!-- Footer -->
        <footer>
            <div class="row">
                <div class="col-lg-12">
                    <p>Copyright &copy; 2014-2017</p>
                </div>
            </div>
        </footer>

    </div>
    <!-- /.container -->

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>


</body>

</html>
