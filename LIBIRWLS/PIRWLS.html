<!DOCTYPE html>
<html lang="en">
    
    <head>
        
        <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge">
                <meta name="viewport" content="width=device-width, initial-scale=1">
                    <meta name="description" content="LIBIRWLS, parallel IRWLS algorithm for SVMs">
                        <meta name="author" content="Roberto Diaz Morales">
                            
                            <title>Install LIBIRWLS</title>
                            
                            <!-- Bootstrap Core CSS -->
                            <link href="css/bootstrap.min.css" rel="stylesheet">
                                
                                <!-- Custom CSS -->
                                <link href="css/modern-business.css" rel="stylesheet">
                                    
                                    <!-- Custom CSS -->
                                    <link href="css/command.css" rel="stylesheet">
                                        
                                        
                                        <!-- Custom Fonts -->
                                        <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
                                            
                                            <!-- USED FOR LATEX CODE INSIDE THE HTML -->
                                            <script type="text/x-mathjax-config">
                                                MathJax.Hub.Config({
                                                                   extensions: ["tex2jax.js"],
                                                                   jax: ["input/TeX","output/HTML-CSS"],
                                                                   tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]}
                                                                   });
                                                </script>
                                            <script type="text/javascript" src="MathJax/MathJax.js"></script>
                                            
                                            <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
                                            <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
                                            <!--[if lt IE 9]>
                                             <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
                                             <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
                                             <![endif]-->
                                            
    </head>
    
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="index.html">LIBIRWLS</a>
        </div>
        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Install<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li>
                            <a href="install.html">Build the library</a>
                        </li>
                        <li>
                            <a href="installpython.html">Python Extension</a>
                        </li>
                    </ul>
                </li>

                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Algorithms <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li>
                            <a href="PIRWLS.html">IRWLS to train a SVM</a>
                        </li>
                        <li>
                            <a href="PSIRWLS.html">IRWLS to train a budgeted SVM</a>
                        </li>
                        <li>
                            <a href="parallelization.html">Parallelization</a>
                        </li>
                    </ul>
                </li>
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Examples<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li>
                            <a href="examplesFiles.html">Command Line guide and Examples</a>
                        </li>
                        <li>
                            <a href="examplesPython.html">Python Extension guide and Examples</a>
                        </li>
                        <li>
                            <a href="examplesDemos.html">Demo folder</a>
                        </li>
                    </ul>
                </li>

                <li>
                    <a href="API/index.html" target="blank">API</a>
                </li>
                <li>
                    <a href="contact.html">Contact</a>
                </li>
                <li><a href="https://github.com/RobeDM/LIBIRWLS" target="blank"><i class="fa fa-github fa-fw fa-lg"></i></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


        <!-- Header Carousel -->
        
        
        <!-- Page Content -->
        <div class="container container-large">
            
            <!-- Marketing Icons Section -->
            <div class="row">
                <div class="col-md-1">
                </div>
                <div class="col-md-10">
                    
                    <hr>
                    
                    <h1>
                        FULL SOLUTION
                    </h1>
                    
                    <hr>
                    
                    <h4>
                        Support Vector Machines
                    </h4>
                    <p>
                    Suppose a binary classification problem with a data set $\mathcal{D}$ that contains $n$ training examples in a $p$-dimensional space of the form:
                    </p>
                    <p align="center">
                    $\mathcal{D}=\{(\mathbf{x}_i,y_i)|\mathbf{x}_i \in \mathbb{R}^p,y_i \in \{-1,1\}\}_{i=1}^{n}$
                    </p>
                    
                    <p>where $y_i$ indicates the class of the training sample $\mathbf{x}_i$.</p>
                    
                    <p>The primal optimization problem to solve a SVM when we use soft margin classification to allow samples inside the classification margin and using a kernel functions is <a href="http://link.springer.com/article/10.1007/bf00994018">(Cortes, 1995)</a>:</p>
                    
                    <p align="center">
                    $\min_{\mathbf{w},b} \frac{1}{2}\Vert\mathbf{w}\Vert^2+C\sum_{i=1}^n{\xi_i}$<br>
                    $y_i(\sum_{j=1}^n\alpha_jy_jK(\mathbf{x}_j\mathbf{x}_i)+b)\ge 1-\xi_i,\forall i=1,2,...,n$<br>
                    $\xi_i \ge 0,\forall i=1,2,...,n$<br>
                    $\mathbf{w}=\sum_{i=1}^{n}y_i\alpha_i\phi(\mathbf{x}_i)$
                    </p>
                    
                    <p>
                    where $C$ is a penalty parameter to tradeoff the misclassification error, $\phi(\cdot)$ is a nonlinear transformation (usually unknown) where inner products can be computed using a kernel function $\phi(\mathbf{x}_i)\phi(\mathbf{x}_j)=K(\mathbf{x}_i,\mathbf{x}_j)$ and $\alpha_i$ is the Lagrange multiplier associated to the constraint of the sample $\mathbf{x}_i$.</p>
                    <p>
                    If the kernel is a radial basis function, also called Gaussian kernel $K(\mathbf{x}_i,\mathbf{x}_j)=exp(-\gamma\Vert \mathbf{x}_i - \mathbf{x}_j \Vert^2)$, the corresponding feature space is a Hilbert space of infinite dimensions.
                    </p>
                    
                    <p>
                    This optimization problem is equivalent to solving an $n$-dimensional convex Quadratic Programming (QP) problem.
                    </p>
                    
                    <p>
                    The solution is non-parametric, the size of the classification function (that is the number of Support Vectors) is not predetermined and is modeled based on the training samples. To keep the complexity under control a semi-parametric models can be adopted (<a href="PSIRWLS.html">see our Budgeted solution</a>).
                    </p>
                    
                    <h4>
                        IRWLS to train a SVM
                    </h4>

                    <p>
                    The cost function of the SVM can be rearranged in the form of a Weighted Least Squares problem <a href="http://papers.nips.cc/paper/1855-fast-training-of-support-vector-classifiers.pdf">(Perez Cruz, 2001)</a>. That matricial formulation, with a complexity that can be kept under control, can be efficiently parallelized as shown in <a href="http://www.sciencedirect.com/science/article/pii/S0167865516302173">(DÃ­az Morales, 2016b)</a>.
                    </p>                    

                    <p>
                    IRWLS rearranges the cost function to be independent of $\xi_i$ <a href="http://papers.nips.cc/paper/1855-fast-training-of-support-vector-classifiers.pdf">(Perez Cruz, 2001)</a>:
                    </p>
                    
                    <p align="center">
                    $\min_{\boldsymbol{\beta},b}  \frac{1}{2}\Vert\mathbf{w}\Vert^2+\sum_{i}a_{i}e_i^2$<br>
                    $e_i=y_i-\left(\sum_{j=1}^n\alpha_jy_jK(\mathbf{x}_i,\mathbf{x}_j)+b\right)$<br>
                    $a_i=\begin{cases}0,y_ie_i \le 0\\\frac{C}{e_iy_i},y_ie_i \ge 0\label{vara}\end{cases}$
                    </p>
                    
                    <p>
                    The weights are then obtained by minimizing the equation considering that $a_i$ does not depend on $\mathbf{w}$, then recalculating $a_i$ using the new $\mathbf{w}$ and repeating the procedure until convergence.
                    </p>
                    
                    <p>
                    In every iteration, the size of the quadratic problem to be solved is equal to the number of elements in the training set. This is not affordable in most of the cases because it is necessary to store in memory a matrix that contains the kernel function of every pair of training samples in order to solve the linear system that obtains in every iteration the weights $\mathbf{w}$. To make this procedure practical two solution have been proposed in the literature.
                    </p>
                    
                    <ul>
                        <li>Training samples differentiation: The linear system does not need to work with the full training set, just with a reduced set that contains the unbounded Support Vectors. It works dividing the training samples into three sets. $\mathcal{S}_1$ contains the unbounded SVs, $\mathcal{S}_2$ contains samples whose $\alpha_i=0$ and $\mathcal{S}_3$ contains bounded SVs. This method, although reduces the complexity of the training procedure, is not enough when the number of unbounded Support Vectors is very high.</li>
                        
                        <li>Using a working set: To use this procedure inside a chunking scheme, we need to use a division of the training elements into two different groups. The samples are divided at every iteration into a working set $\mathcal{S}_W$ that is fixed in size, whose elements have the weights that are going to be updated in an iteration, and an inactive set $S_{IN}$, which contains the elements whose weights remain constant. The size of the quadratic problem is the working set size, allowing us to keep the complexity under control.</li>
                    </ul>
                    
                    <p>
                    This software makes use of both methods to solve a full SVM: we use training samples differentiation and there is an outer loop that selects a working set in every iteration and an inner loop that updates the weights of the working set using the IRWLS procedure.
                    </p>


                    <p>
                    To parallelize this software, a shared memory parallelization has been performed as described in <a href="http://www.sciencedirect.com/science/article/pii/S0167865516302173">(DÃ­az Morales, 2016b)</a>.
                    </p>
                    <hr>
                </div>
            </div>
            <!-- Footer -->
            <footer>
                <div class="row">
                    <div class="col-lg-12">
                        <p>Copyright &copy; 2014-2017</p>
                    </div>
                </div>
            </footer>
            
        </div>
        <!-- /.container -->
        
        <!-- jQuery -->
        <script src="js/jquery.js"></script>
        
        <!-- Bootstrap Core JavaScript -->
        <script src="js/bootstrap.min.js"></script>
        
        <!-- Script to Activate the Carousel -->
        <script>
            $('.carousel').carousel({
                                    interval: 5000 //changes the speed
                                    })
            </script>
        
    </body>
    
</html>
